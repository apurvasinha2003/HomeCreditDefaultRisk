{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!!!!Credit Risk Data Challenge!!!                                                                  \n",
    "A Learner project with RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"C:\\\\Users\\\\Apurva\\\\Downloads\\\\courses\\\\credit-risk-challenge\\\\data\\\\application_train\"\n",
    "root_b = \"C:\\\\Users\\\\Apurva\\\\Downloads\\\\courses\\\\credit-risk-challenge\\\\data\\\\bureau\"\n",
    "root_cc = \"C:\\\\Users\\\\Apurva\\\\Downloads\\\\courses\\\\credit-risk-challenge\\\\data\\\\credit_card_balance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the main data file!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#This is our main data-set file. We need to join this \n",
    "#main dataframe with other dataframes to get more features.\n",
    "master = open( root + \"\\\\application_train.csv\",'r')\n",
    "\n",
    "fields = ['SK_ID_CURR','TARGET','NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY'\n",
    "          ,'CNT_CHILDREN','AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE',\n",
    "          'NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS',\n",
    "          'NAME_HOUSING_TYPE','REGION_POPULATION_RELATIVE','DAYS_BIRTH','DAYS_EMPLOYED'\n",
    "          ,'DAYS_REGISTRATION','DAYS_ID_PUBLISH','OWN_CAR_AGE','FLAG_PHONE','OCCUPATION_TYPE',\n",
    "          'CNT_FAM_MEMBERS','REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY',\n",
    "          'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY','ORGANIZATION_TYPE',\n",
    "          'LIVE_CITY_NOT_WORK_CITY','APARTMENTS_AVG','BASEMENTAREA_AVG',\n",
    "          'YEARS_BEGINEXPLUATATION_AVG','YEARS_BUILD_AVG','EXT_SOURCE_1','EXT_SOURCE_2'\n",
    "           ,'EXT_SOURCE_3', 'AMT_REQ_CREDIT_BUREAU_YEAR','YEARS_BEGINEXPLUATATION_AVG',\n",
    "          'APARTMENTS_AVG','YEARS_BUILD_AVG','COMMONAREA_AVG','ELEVATORS_AVG','YEARS_BUILD_MODE',\n",
    "          'APARTMENTS_MEDI','YEARS_BEGINEXPLUATATION_MEDI','LANDAREA_MEDI','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "          'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\n",
    "          'AMT_REQ_CREDIT_BUREAU_QRT']\n",
    "\n",
    "df = pd.read_csv(master, usecols=fields) # load application_train.csv in dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert every feature to a number!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cash loans' 'Revolving loans']\n['M' 'F' 'XNA']\n['N' 'Y']\n['Y' 'N']\n['Unaccompanied' 'Family' 'Spouse, partner' 'Children' 'Other_A' 0\n 'Other_B' 'Group of people']\n['Working' 'State servant' 'Commercial associate' 'Pensioner' 'Unemployed'\n 'Student' 'Businessman' 'Maternity leave']\n['Secondary / secondary special' 'Higher education' 'Incomplete higher'\n 'Lower secondary' 'Academic degree']\n['Single / not married' 'Married' 'Civil marriage' 'Widow' 'Separated'\n 'Unknown']\n['House / apartment' 'Rented apartment' 'With parents'\n 'Municipal apartment' 'Office apartment' 'Co-op apartment']\n['Laborers' 'Core staff' 'Accountants' 'Managers' 0 'Drivers'\n 'Sales staff' 'Cleaning staff' 'Cooking staff' 'Private service staff'\n 'Medicine staff' 'Security staff' 'High skill tech staff'\n 'Waiters/barmen staff' 'Low-skill Laborers' 'Realty agents' 'Secretaries'\n 'IT staff' 'HR staff']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business Entity Type 3' 'School' 'Government' 'Religion' 'Other' 'XNA'\n 'Electricity' 'Medicine' 'Business Entity Type 2' 'Self-employed'\n 'Transport: type 2' 'Construction' 'Housing' 'Kindergarten'\n 'Trade: type 7' 'Industry: type 11' 'Military' 'Services'\n 'Security Ministries' 'Transport: type 4' 'Industry: type 1' 'Emergency'\n 'Security' 'Trade: type 2' 'University' 'Transport: type 3' 'Police'\n 'Business Entity Type 1' 'Postal' 'Industry: type 4' 'Agriculture'\n 'Restaurant' 'Culture' 'Hotel' 'Industry: type 7' 'Trade: type 3'\n 'Industry: type 3' 'Bank' 'Industry: type 9' 'Insurance' 'Trade: type 6'\n 'Industry: type 2' 'Transport: type 1' 'Industry: type 12' 'Mobile'\n 'Trade: type 1' 'Industry: type 5' 'Industry: type 10' 'Legal Services'\n 'Advertising' 'Trade: type 5' 'Cleaning' 'Industry: type 13'\n 'Trade: type 4' 'Telecom' 'Industry: type 8' 'Realtor' 'Industry: type 6']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n[-1  1  0]\n[ 1 -1]\n[-1  1]\n[1 2 3 4 5 0 6 7]\n[1 2 3 4 5 6 7 8]\n[1 2 3 4 5]\n[1 2 3 4 5 6]\n[1 2 3 4 5 6]\n[ 1  2  3  4  0  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n 49 50 51 52 53 54 55 56 57 58]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#function to transfer non numeric fields to numeric fields\n",
    "def initital_cleaning(df):\n",
    "    df.replace(np.nan, 0, inplace=True)\n",
    "    print(df['NAME_CONTRACT_TYPE'].unique())\n",
    "    print(df['CODE_GENDER'].unique())\n",
    "    print(df['FLAG_OWN_CAR'].unique())\n",
    "    print(df['FLAG_OWN_REALTY'].unique())\n",
    "    print(df['NAME_TYPE_SUITE'].unique())\n",
    "    print(df['NAME_INCOME_TYPE'].unique())\n",
    "    print(df['NAME_EDUCATION_TYPE'].unique())\n",
    "    print(df['NAME_FAMILY_STATUS'].unique())\n",
    "    print(df['NAME_HOUSING_TYPE'].unique())\n",
    "    print(df['OCCUPATION_TYPE'].unique())\n",
    "    print(df['ORGANIZATION_TYPE'].unique())\n",
    "    \n",
    "    df['NAME_CONTRACT_TYPE'] = df['NAME_CONTRACT_TYPE'].map({0: 0, 'Cash loans': -1, 'Revolving loans': 1})\n",
    "    df['CODE_GENDER'] = df['CODE_GENDER'].map({0: 0, 'M': -1, 'F': 1, 'XNA': 0})\n",
    "    df['FLAG_OWN_CAR'] = df['FLAG_OWN_CAR'].map({0: 0, 'N': 1, 'Y': -1})\n",
    "    df['FLAG_OWN_REALTY'] = df['FLAG_OWN_REALTY'].map({0: 0, 'N': 1, 'Y': -1})\n",
    "    df['NAME_TYPE_SUITE'] = df['NAME_TYPE_SUITE'].map({0: 0, 'Unaccompanied': 1, 'Family': 2\n",
    "                                                          , 'Spouse, partner': 3, 'Children': 4, 'Other_A': 5,\n",
    "                                                       'Other_B': 6, 'Group of people': 7})\n",
    "    df['NAME_INCOME_TYPE'] = df['NAME_INCOME_TYPE'].map(\n",
    "        {'Working': 1, 'State servant': 2, 'Commercial associate': 3, 'Pensioner': 4, 'Unemployed': 5,\n",
    "         'Student': 6, 'Businessman': 7, 'Maternity leave': 8})\n",
    "    df['NAME_EDUCATION_TYPE'] = df['NAME_EDUCATION_TYPE'].map(\n",
    "        {'Secondary / secondary special': 1, 'Higher education': 2, 'Incomplete higher': 3,\n",
    "         'Lower secondary': 4, 'Academic degree': 5})\n",
    "    df['NAME_FAMILY_STATUS'] = df['NAME_FAMILY_STATUS'].map(\n",
    "        {'Single / not married': 1, 'Married': 2, 'Civil marriage': 3, 'Widow': 4, 'Separated': 5,\n",
    "         'Unknown': 6})\n",
    "    df['NAME_HOUSING_TYPE'] = df['NAME_HOUSING_TYPE'].map({'House / apartment': 1, 'Rented apartment': 2, 'With parents': 3,\n",
    "                                                           'Municipal apartment': 4, 'Office apartment': 5,\n",
    "                                                           'Co-op apartment': 6})\n",
    "    df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].map(\n",
    "        {'Laborers': 1, 'Core staff': 2, 'Accountants': 3, 'Managers': 4, 0: 0, 'Drivers': 5,\n",
    "         'Sales staff': 6, 'Cleaning staff': 7, 'Cooking staff': 8, 'Private service staff': 9,\n",
    "         'Medicine staff': 10, 'Security staff': 11, 'High skill tech staff': 12,\n",
    "         'Waiters/barmen staff': 13, 'Low-skill Laborers': 14, 'Realty agents': 15, 'Secretaries': 16,\n",
    "         'IT staff': 17, 'HR staff': 18})\n",
    "    df['ORGANIZATION_TYPE'] = df['ORGANIZATION_TYPE'].map(\n",
    "        {0: 0, 'Business Entity Type 3': 1, 'School': 2, 'Government': 3, 'Religion': 4, 'Other': 5, 'XNA': 6,\n",
    "         'Electricity': 7, 'Medicine': 8, 'Business Entity Type 2': 9, 'Self-employed': 10,\n",
    "         'Transport: type 2': 11, 'Construction': 12, 'Housing': 13, 'Kindergarten': 14,\n",
    "         'Trade: type 7': 15, 'Industry: type 11': 16, 'Military': 17, 'Services': 18,\n",
    "         'Security Ministries': 19, 'Transport: type 4': 20, 'Industry: type 1': 21, 'Emergency': 22,\n",
    "         'Security': 23, 'Trade: type 2': 24, 'University': 25, 'Transport: type 3': 26, 'Police': 27,\n",
    "         'Business Entity Type 1': 28, 'Postal': 29, 'Industry: type 4': 30, 'Agriculture': 31,\n",
    "         'Restaurant': 32, 'Culture': 33, 'Hotel': 34, 'Industry: type 7': 35, 'Trade: type 3': 36,\n",
    "         'Industry: type 3': 37, 'Bank': 38, 'Industry: type 9': 39, 'Insurance': 40, 'Trade: type 6': 41,\n",
    "         'Industry: type 2': 42, 'Transport: type 1': 43, 'Industry: type 12': 44, 'Mobile': 45,\n",
    "         'Trade: type 1': 46, 'Industry: type 5': 47, 'Industry: type 10': 48, 'Legal Services': 49,\n",
    "         'Advertising': 50, 'Trade: type 5': 51, 'Cleaning': 52, 'Industry: type 13': 53,\n",
    "         'Trade: type 4': 54, 'Telecom': 55, 'Industry: type 8': 56, 'Realtor': 57, 'Industry: type 6': 58})\n",
    "    \n",
    "    print(df['NAME_CONTRACT_TYPE'].unique())\n",
    "    print(df['CODE_GENDER'].unique())\n",
    "    print(df['FLAG_OWN_CAR'].unique())\n",
    "    print(df['FLAG_OWN_REALTY'].unique())\n",
    "    print(df['NAME_TYPE_SUITE'\n",
    "             ''].unique())\n",
    "    print(df['NAME_INCOME_TYPE'].unique())\n",
    "    print(df['NAME_EDUCATION_TYPE'].unique())\n",
    "    print(df['NAME_FAMILY_STATUS'].unique())\n",
    "    print(df['NAME_HOUSING_TYPE'].unique())\n",
    "    print(df['OCCUPATION_TYPE'].unique())\n",
    "    print(df['ORGANIZATION_TYPE'].unique())\n",
    "    return df\n",
    "    \n",
    "print(df['TARGET'].unique())\n",
    "df = initital_cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize and split into 80:20 !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AMT_CREDIT_MAX_OVERDUE\n",
    "bureau = open( root_b + \"\\\\bureau.csv\",'r')\n",
    "overduemap = {}\n",
    "skip=True\n",
    "for line in bureau.readlines():\n",
    "    if skip:\n",
    "        skip=False\n",
    "        continue\n",
    "    s = line.split(',')\n",
    "    id = int(s[0])\n",
    "    overdue = 0\n",
    "    if s[8] is None or s[8] == '':\n",
    "        continue\n",
    "    else:\n",
    "        overdue = float(s[8])\n",
    "    a=overduemap.get(id,None)\n",
    "    if a is None:\n",
    "        overduemap[id] = overdue\n",
    "    else:\n",
    "        overduemap[id] = a + overdue\n",
    "\n",
    "previous = open( root + \"\\\\previous_application.csv\",'r')\n",
    "skip=True\n",
    "existsmap = {}\n",
    "refusedmap = {}\n",
    "refusedtypemap = {}\n",
    "cancelledmap = {}\n",
    "cancelledtypemap = {}\n",
    "for line in previous.readlines():\n",
    "    if skip:\n",
    "        skip=False\n",
    "        continue\n",
    "    s = line.split(',')\n",
    "    id = int(s[1])\n",
    "    status = s[16]\n",
    "    type = -1\n",
    "    if s[2] == 'Consumer loans':\n",
    "        type = 0\n",
    "    elif s[2] == 'Cash loans':\n",
    "        type =-1\n",
    "    elif s[2] == 'Revolving loans':\n",
    "        type =1\n",
    "    if status == 'Refused':\n",
    "        refusedmap[id] = 1\n",
    "        refusedtypemap[str(id)+str(type)] = 1\n",
    "    elif status == 'Canceled':\n",
    "        cancelledmap[id] = 1\n",
    "        cancelledtypemap[str(id)+str(type)] = 1\n",
    "    elif status == 'Approved':\n",
    "        val = refusedmap.get(id, None)\n",
    "        if val is None:\n",
    "            refusedmap[id] = -1\n",
    "    existsmap[id]=1\n",
    "    \n",
    "def populate_bureau_features(df):\n",
    "    overdues = []\n",
    "    exists = []\n",
    "    refused = []\n",
    "    cancelled = []\n",
    "    refusedtype = []\n",
    "    cancelledtype = []\n",
    "    for i, row in df.iterrows():\n",
    "        value = overduemap.get(df.at[i,'SK_ID_CURR'], -1)\n",
    "        overdues.append(value)\n",
    "        id = df.at[i,'SK_ID_CURR']\n",
    "        type = df.at[i,'NAME_CONTRACT_TYPE']\n",
    "        key = str(id) + str(type)\n",
    "        refused.append(refusedmap.get(id, 0))\n",
    "        cancelled.append(cancelledmap.get(id, 0))\n",
    "        refusedtype.append(refusedtypemap.get(key, 0))\n",
    "        cancelledtype.append(cancelledtypemap.get(key, 0))\n",
    "        exists.append(existsmap.get(id, 0))\n",
    "        \n",
    "    df['PREVIOUS_EXISTS'] = exists\n",
    "    df['REFUSED'] = refused\n",
    "    df['CANCELLED'] = cancelled\n",
    "    df['CANCELLED_TYPE'] = cancelledtype\n",
    "    df['REFUSED_TYPE'] = refusedtype\n",
    "    df['AMT_CREDIT_MAX_OVERDUE_1'] = overdues\n",
    "    return df\n",
    "\n",
    "df = populate_bureau_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Started adding credit card balance to dataframe::\n"
     ]
    }
   ],
   "source": [
    "credit_card = open(root_cc + \"\\\\credit_card_balance.csv\", 'r')\n",
    "balancemap = {}\n",
    "limitmap = {}\n",
    "atmmap = {}\n",
    "atmdmap = {}\n",
    "skip = True\n",
    "for line in credit_card.readlines():\n",
    "    if skip:\n",
    "        skip = False\n",
    "        continue\n",
    "    s = line.split(',')\n",
    "    id = int(s[1])\n",
    "    balance = 0\n",
    "    try:\n",
    "        balance = float(s[3])\n",
    "    except ValueError:\n",
    "        balance = 0\n",
    "\n",
    "    limit = 0\n",
    "    try:\n",
    "        limit = float(s[4])\n",
    "    except:\n",
    "        limit = 0\n",
    "    atm = 0\n",
    "    try:\n",
    "        atm = float(s[7])\n",
    "    except:\n",
    "        atm = 0\n",
    "    atm_d = 0\n",
    "    try:\n",
    "        atm_d = float(s[16])\n",
    "    except:\n",
    "        atm_d = 0\n",
    "\n",
    "    a = limitmap.get(id, None)\n",
    "    if balance is None or balance == '':\n",
    "        continue\n",
    "    if a is None:\n",
    "        limitmap[id] = limit\n",
    "        balancemap[id] = balance\n",
    "        atmmap[id] = atm\n",
    "        atmdmap[id] = atm_d\n",
    "    else:\n",
    "        limitmap[id] = a + limit\n",
    "        balancemap[id] = balancemap[id] + balance\n",
    "        atmmap[id] = balancemap[id] + atm\n",
    "        atmdmap[id] = balancemap[id] + atm_d\n",
    "\n",
    "print('::Started adding credit card balance to dataframe::')\n",
    "\n",
    "def populate_credit_card_features(df):\n",
    "    balanceratio = []\n",
    "    atmratio = []\n",
    "    atmdratio =[]\n",
    "    for i, row in df.iterrows():\n",
    "        limit = limitmap.get(df.at[i, 'SK_ID_CURR'], 1)\n",
    "        if limit == 0 or limit == 0.0:\n",
    "            limit = 1\n",
    "        balance = balancemap.get(df.at[i, 'SK_ID_CURR'], -1)\n",
    "        balanceratio.append(balance / limit)\n",
    "        atmratio.append(atmmap.get(df.at[i, 'SK_ID_CURR'], -1) / limit)\n",
    "        atmdratio.append(atmdmap.get(df.at[i, 'SK_ID_CURR'], -1) / limit)\n",
    "    \n",
    "    df['BALANCE_RATIO'] = balanceratio\n",
    "    df['ATM_RATIO'] = atmratio\n",
    "    df['ATM_D_RATIO'] = atmdratio\n",
    "    return df\n",
    "\n",
    "df = populate_credit_card_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -1.   100. -1000.     1.  -100.  1000.    10.     0.]\n"
     ]
    }
   ],
   "source": [
    "bureau = open( root_b + \"\\\\bureau.csv\",'r')\n",
    "\n",
    "def add_merged_features(bureau , df1):\n",
    "    b_cols = ['SK_ID_CURR','DAYS_CREDIT','CREDIT_DAY_OVERDUE','DAYS_CREDIT_ENDDATE','AMT_ANNUITY',\n",
    "              'DAYS_ENDDATE_FACT','AMT_CREDIT_MAX_OVERDUE','CNT_CREDIT_PROLONG','AMT_CREDIT_SUM',\n",
    "              'AMT_CREDIT_SUM_DEBT','AMT_CREDIT_SUM_LIMIT','AMT_CREDIT_SUM_OVERDUE','DAYS_CREDIT_UPDATE'\n",
    "            ]\n",
    "    df_bureau = pd.read_csv(bureau, usecols=b_cols)\n",
    "    df_bureau.replace(np.nan, 0, inplace=True)\n",
    "    df_bureau = df_bureau.groupby(['SK_ID_CURR'], as_index=True )['DAYS_CREDIT','CREDIT_DAY_OVERDUE','DAYS_CREDIT_ENDDATE','AMT_ANNUITY',\n",
    "              'DAYS_ENDDATE_FACT','AMT_CREDIT_MAX_OVERDUE','CNT_CREDIT_PROLONG','AMT_CREDIT_SUM',\n",
    "              'AMT_CREDIT_SUM_DEBT','AMT_CREDIT_SUM_LIMIT','AMT_CREDIT_SUM_OVERDUE','DAYS_CREDIT_UPDATE'].mean().reset_index()\n",
    "    \n",
    "    df1 = df1.merge(df_bureau, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    credit_card = open(root_cc + \"\\\\credit_card_balance.csv\", 'r')\n",
    "    c_cols = ['SK_ID_CURR','MONTHS_BALANCE','AMT_BALANCE','AMT_CREDIT_LIMIT_ACTUAL','AMT_DRAWINGS_ATM_CURRENT',\n",
    "              'AMT_DRAWINGS_CURRENT','AMT_DRAWINGS_OTHER_CURRENT','AMT_DRAWINGS_POS_CURRENT','AMT_INST_MIN_REGULARITY',\n",
    "              'AMT_PAYMENT_CURRENT','AMT_PAYMENT_TOTAL_CURRENT','AMT_RECEIVABLE_PRINCIPAL','AMT_RECIVABLE','AMT_TOTAL_RECEIVABLE',\n",
    "              'CNT_DRAWINGS_ATM_CURRENT','CNT_DRAWINGS_CURRENT','CNT_DRAWINGS_OTHER_CURRENT','CNT_DRAWINGS_POS_CURRENT','CNT_INSTALMENT_MATURE_CUM','SK_DPD',\n",
    "              'SK_DPD_DEF']\n",
    "    \n",
    "    df_cc = pd.read_csv(credit_card, usecols=c_cols)\n",
    "    df_cc.replace(np.nan, 0, inplace=True)\n",
    "    df_cc = df_cc.groupby(['SK_ID_CURR'], as_index=True )['MONTHS_BALANCE','AMT_BALANCE','AMT_CREDIT_LIMIT_ACTUAL','AMT_DRAWINGS_ATM_CURRENT',\n",
    "              'AMT_DRAWINGS_CURRENT','AMT_DRAWINGS_OTHER_CURRENT','AMT_DRAWINGS_POS_CURRENT','AMT_INST_MIN_REGULARITY',\n",
    "              'AMT_PAYMENT_CURRENT','AMT_PAYMENT_TOTAL_CURRENT','AMT_RECEIVABLE_PRINCIPAL','AMT_RECIVABLE','AMT_TOTAL_RECEIVABLE',\n",
    "              'CNT_DRAWINGS_ATM_CURRENT','CNT_DRAWINGS_CURRENT','CNT_DRAWINGS_OTHER_CURRENT','CNT_DRAWINGS_POS_CURRENT','CNT_INSTALMENT_MATURE_CUM','SK_DPD',\n",
    "              'SK_DPD_DEF'].mean().reset_index()\n",
    "    \n",
    "    df1 = df1.merge(df_cc, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    pos_cols = ['SK_ID_CURR','MONTHS_BALANCE','CNT_INSTALMENT','CNT_INSTALMENT_FUTURE','NAME_CONTRACT_STATUS',\n",
    "     'SK_DPD','SK_DPD_DEF','NAME_CONTRACT_STATUS']\n",
    "    pos = open(root + \"\\\\POS_CASH_balance.csv\", 'r')\n",
    "    df_pos = pd.read_csv(pos, usecols=pos_cols)\n",
    "    df_pos['NAME_CONTRACT_STATUS'] = df_pos['NAME_CONTRACT_STATUS'].map({'Active': -1, 'Approved': 1, 'Canceled': 10,\n",
    "                                                           'Completed': 100, 'Demand': 1000,\n",
    "                                                           'Returned to the store': -100,'Signed':-1000})\n",
    "    \n",
    "    df_pos.replace(np.nan, 0, inplace=True)\n",
    "    print(df_pos['NAME_CONTRACT_STATUS'].unique())\n",
    "    df_pos = df_pos.groupby(['SK_ID_CURR'], as_index=True )['MONTHS_BALANCE','CNT_INSTALMENT',\n",
    "                                       'CNT_INSTALMENT_FUTURE','NAME_CONTRACT_STATUS'].mean().reset_index()\n",
    "    \n",
    "    df1 = df1.merge(df_pos, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    inst_cols = ['SK_ID_CURR','NUM_INSTALMENT_VERSION',\n",
    "                 'NUM_INSTALMENT_NUMBER','DAYS_INSTALMENT',\n",
    "                 'DAYS_ENTRY_PAYMENT','AMT_INSTALMENT','AMT_PAYMENT']\n",
    "    df_inst = pd.read_csv(inst, usecols=inst_cols)\n",
    "    df_inst.replace(np.nan, 0, inplace=True)\n",
    "    df_inst = df_inst.groupby(    inst = open(root + \"\\\\installments_payments.csv\", 'r')\n",
    "['SK_ID_CURR'], as_index=True )['NUM_INSTALMENT_VERSION','NUM_INSTALMENT_NUMBER','DAYS_INSTALMENT',\n",
    "            'DAYS_ENTRY_PAYMENT','AMT_INSTALMENT','AMT_PAYMENT'].mean().reset_index()\n",
    "    \n",
    "    df1 = df1.merge(df_inst, on='SK_ID_CURR', how='left')\n",
    "    return df1\n",
    "df = add_merged_features(bureau, df)\n",
    "bureau.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n       'AMT_CREDIT', 'AMT_ANNUITY_x',\n       ...\n       'MONTHS_BALANCE_y', 'CNT_INSTALMENT', 'CNT_INSTALMENT_FUTURE',\n       'NAME_CONTRACT_STATUS', 'NUM_INSTALMENT_VERSION',\n       'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT', 'DAYS_ENTRY_PAYMENT',\n       'AMT_INSTALMENT', 'AMT_PAYMENT'],\n      dtype='object', length=101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70440 59394 59394 59572 100294 110726 95000 57203\n"
     ]
    }
   ],
   "source": [
    "overdue = 0\n",
    "balance = 0 \n",
    "atm = 0\n",
    "atm_d = 0\n",
    "refused1 =0\n",
    "cancelled1 = 0\n",
    "refusedtype1 = 0\n",
    "cancelledtype1 = 0 \n",
    "print(df.columns)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if df.at[i,'BALANCE_RATIO'] > 0.0:\n",
    "        balance = balance + 1\n",
    "    if df.at[i,'AMT_CREDIT_MAX_OVERDUE_1'] > 0.0:\n",
    "        overdue = overdue + 1 \n",
    "    if df.at[i,'ATM_RATIO'] > 0.0:\n",
    "        atm = atm + 1\n",
    "    if df.at[i,'ATM_RATIO'] > 0.0:\n",
    "        atm_d = atm_d + 1\n",
    "    if df.at[i,'REFUSED'] > 0.0:\n",
    "        refused1 = refused1 + 1 \n",
    "    if df.at[i,'REFUSED_TYPE'] > 0.0:\n",
    "        refusedtype1 = refusedtype1 + 1\n",
    "    if df.at[i,'CANCELLED'] > 0.0:\n",
    "        cancelled1 = cancelled1 + 1\n",
    "    if df.at[i,'CANCELLED_TYPE'] > 0.0:\n",
    "        cancelledtype1 = cancelledtype1 + 1\n",
    "print(overdue,atm,atm_d,balance, refused1, cancelled1, cancelledtype1, refusedtype1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAME_CONTRACT_TYPE' 'CODE_GENDER' 'FLAG_OWN_CAR' 'FLAG_OWN_REALTY'\n 'CNT_CHILDREN' 'AMT_INCOME_TOTAL' 'AMT_CREDIT' 'AMT_ANNUITY_x'\n 'AMT_GOODS_PRICE' 'NAME_TYPE_SUITE' 'NAME_INCOME_TYPE'\n 'NAME_EDUCATION_TYPE' 'NAME_FAMILY_STATUS' 'NAME_HOUSING_TYPE'\n 'REGION_POPULATION_RELATIVE' 'DAYS_BIRTH' 'DAYS_EMPLOYED'\n 'DAYS_REGISTRATION' 'DAYS_ID_PUBLISH' 'OWN_CAR_AGE' 'FLAG_PHONE'\n 'OCCUPATION_TYPE' 'CNT_FAM_MEMBERS' 'REGION_RATING_CLIENT'\n 'REGION_RATING_CLIENT_W_CITY' 'REG_CITY_NOT_LIVE_CITY'\n 'REG_CITY_NOT_WORK_CITY' 'LIVE_CITY_NOT_WORK_CITY' 'ORGANIZATION_TYPE'\n 'EXT_SOURCE_1' 'EXT_SOURCE_2' 'EXT_SOURCE_3' 'APARTMENTS_AVG'\n 'BASEMENTAREA_AVG' 'YEARS_BEGINEXPLUATATION_AVG' 'YEARS_BUILD_AVG'\n 'COMMONAREA_AVG' 'ELEVATORS_AVG' 'YEARS_BUILD_MODE' 'APARTMENTS_MEDI'\n 'YEARS_BEGINEXPLUATATION_MEDI' 'LANDAREA_MEDI'\n 'AMT_REQ_CREDIT_BUREAU_HOUR' 'AMT_REQ_CREDIT_BUREAU_DAY'\n 'AMT_REQ_CREDIT_BUREAU_WEEK' 'AMT_REQ_CREDIT_BUREAU_MON'\n 'AMT_REQ_CREDIT_BUREAU_QRT' 'AMT_REQ_CREDIT_BUREAU_YEAR'\n 'PREVIOUS_EXISTS' 'REFUSED' 'CANCELLED' 'CANCELLED_TYPE' 'REFUSED_TYPE'\n 'AMT_CREDIT_MAX_OVERDUE_1' 'BALANCE_RATIO' 'ATM_RATIO' 'ATM_D_RATIO'\n 'DAYS_CREDIT' 'CREDIT_DAY_OVERDUE' 'DAYS_CREDIT_ENDDATE' 'AMT_ANNUITY_y'\n 'DAYS_ENDDATE_FACT' 'AMT_CREDIT_MAX_OVERDUE' 'CNT_CREDIT_PROLONG'\n 'AMT_CREDIT_SUM' 'AMT_CREDIT_SUM_DEBT' 'AMT_CREDIT_SUM_LIMIT'\n 'AMT_CREDIT_SUM_OVERDUE' 'DAYS_CREDIT_UPDATE' 'MONTHS_BALANCE_x'\n 'AMT_BALANCE' 'AMT_CREDIT_LIMIT_ACTUAL' 'AMT_DRAWINGS_ATM_CURRENT'\n 'AMT_DRAWINGS_CURRENT' 'AMT_DRAWINGS_OTHER_CURRENT'\n 'AMT_DRAWINGS_POS_CURRENT' 'AMT_INST_MIN_REGULARITY'\n 'AMT_PAYMENT_CURRENT' 'AMT_PAYMENT_TOTAL_CURRENT'\n 'AMT_RECEIVABLE_PRINCIPAL' 'AMT_RECIVABLE' 'AMT_TOTAL_RECEIVABLE'\n 'CNT_DRAWINGS_ATM_CURRENT' 'CNT_DRAWINGS_CURRENT'\n 'CNT_DRAWINGS_OTHER_CURRENT' 'CNT_DRAWINGS_POS_CURRENT'\n 'CNT_INSTALMENT_MATURE_CUM' 'SK_DPD' 'SK_DPD_DEF' 'MONTHS_BALANCE_y'\n 'CNT_INSTALMENT' 'CNT_INSTALMENT_FUTURE' 'NAME_CONTRACT_STATUS'\n 'NUM_INSTALMENT_VERSION' 'NUM_INSTALMENT_NUMBER' 'DAYS_INSTALMENT'\n 'DAYS_ENTRY_PAYMENT' 'AMT_INSTALMENT' 'AMT_PAYMENT']\n99\nRows in Training Set 276759\nLength of test set is::30751\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "#df = df.drop(['NAME_CONTRACT_TYPE'],axis=1,inplace=False)\n",
    "\n",
    "size = df.__len__()\n",
    "print(size)\n",
    "partition_index=int(0.9*size)\n",
    "\n",
    "train = df.iloc[:partition_index]\n",
    "train_labels= train['TARGET']\n",
    "train = train.drop(['SK_ID_CURR','TARGET'], axis=1, inplace=False)\n",
    "print(train.columns.values)\n",
    "print(len(train.columns.values))\n",
    "print('Rows in Training Set '+ str(train.__len__()))\n",
    "\n",
    "test = df.iloc[partition_index+1:]\n",
    "test_labels=test['TARGET']\n",
    "test = test.drop(['SK_ID_CURR','TARGET'], axis=1, inplace=False)\n",
    "print('Length of test set is::' +str(test.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n           max_features=20, max_leaf_nodes=None, min_impurity_decrease=0.0,\n           min_impurity_split=None, min_samples_leaf=20,\n           min_samples_split=20, min_weight_fraction_leaf=0.0,\n           n_estimators=100, n_jobs=-1, oob_score=False, random_state=42,\n           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "train.replace(np.nan, 0, inplace=True)\n",
    "regressor = RandomForestRegressor(n_estimators = 100, n_jobs=-1, max_depth = 15,\n",
    "            max_features=20,random_state=42,\n",
    "        min_samples_leaf=20, min_samples_split=20)\n",
    "regressor.fit(train, train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loan approvals in data :: 28247\nNumber of loan denials in data :: 2504\nCorrect Rejects:: 758\nIncorrect Rejects:: 1959\nRecall::  0.3027156549520767\nCorrect Prediction:: 27046\nIncorrect Prediction:: 3705\nAccuracy of model is :: 0.8795161132971285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14564816e-04 9.38450731e-03 1.55261847e-03 1.68545244e-03\n 1.80480683e-03 1.44420510e-02 1.77598482e-02 2.76329558e-02\n 1.38375305e-02 1.28410817e-03 5.38857383e-03 5.10631638e-03\n 4.21760709e-03 1.48462354e-03 1.79747430e-02 3.83681662e-02\n 2.71479943e-02 2.56344110e-02 2.63910166e-02 6.44614759e-03\n 1.03982799e-03 9.53045137e-03 2.73869878e-03 1.55607873e-03\n 1.63179882e-03 1.40084076e-03 1.78943747e-03 1.18511747e-03\n 1.20564033e-02 2.97911466e-02 1.40432916e-01 1.18033972e-01\n 3.55399555e-03 4.08108955e-03 3.84116634e-03 1.61056976e-03\n 2.96788501e-03 9.22367200e-04 1.59534917e-03 3.29963660e-03\n 3.87846328e-03 4.53212699e-03 4.00818194e-06 3.61178310e-05\n 8.91073958e-05 5.61704082e-04 8.71991042e-04 4.69404612e-03\n 4.04347888e-05 4.77530046e-03 1.18429877e-03 1.27202169e-03\n 7.35486080e-03 7.80389757e-03 6.53444818e-03 3.49768150e-03\n 2.83994436e-03 1.87434173e-02 1.08394983e-04 1.99747066e-02\n 4.98343874e-03 1.16043105e-02 7.38599788e-03 3.30463196e-04\n 2.12010050e-02 2.36994042e-02 3.68206491e-03 2.07911804e-03\n 1.43814626e-02 2.20515965e-03 1.10927558e-03 3.11940497e-03\n 3.12986119e-03 2.45436386e-03 2.89588877e-04 1.34041729e-03\n 1.60716092e-03 2.85541822e-03 2.06565988e-03 1.00015898e-03\n 6.04192054e-04 5.77037791e-04 1.22009505e-02 5.40864144e-03\n 1.54039893e-04 2.24733173e-03 1.63107111e-03 9.56792119e-04\n 5.36011859e-04 1.68635147e-02 1.76681674e-02 2.84849786e-02\n 2.12964682e-02 1.32879749e-02 1.90135039e-02 1.16900922e-02\n 1.36146886e-02 1.88191749e-02 2.47078697e-02]\n99\n['NAME_CONTRACT_TYPE' 'CODE_GENDER' 'FLAG_OWN_CAR' 'FLAG_OWN_REALTY'\n 'CNT_CHILDREN' 'AMT_INCOME_TOTAL' 'AMT_CREDIT' 'AMT_ANNUITY_x'\n 'AMT_GOODS_PRICE' 'NAME_TYPE_SUITE' 'NAME_INCOME_TYPE'\n 'NAME_EDUCATION_TYPE' 'NAME_FAMILY_STATUS' 'NAME_HOUSING_TYPE'\n 'REGION_POPULATION_RELATIVE' 'DAYS_BIRTH' 'DAYS_EMPLOYED'\n 'DAYS_REGISTRATION' 'DAYS_ID_PUBLISH' 'OWN_CAR_AGE' 'FLAG_PHONE'\n 'OCCUPATION_TYPE' 'CNT_FAM_MEMBERS' 'REGION_RATING_CLIENT'\n 'REGION_RATING_CLIENT_W_CITY' 'REG_CITY_NOT_LIVE_CITY'\n 'REG_CITY_NOT_WORK_CITY' 'LIVE_CITY_NOT_WORK_CITY' 'ORGANIZATION_TYPE'\n 'EXT_SOURCE_1' 'EXT_SOURCE_2' 'EXT_SOURCE_3' 'APARTMENTS_AVG'\n 'BASEMENTAREA_AVG' 'YEARS_BEGINEXPLUATATION_AVG' 'YEARS_BUILD_AVG'\n 'COMMONAREA_AVG' 'ELEVATORS_AVG' 'YEARS_BUILD_MODE' 'APARTMENTS_MEDI'\n 'YEARS_BEGINEXPLUATATION_MEDI' 'LANDAREA_MEDI'\n 'AMT_REQ_CREDIT_BUREAU_HOUR' 'AMT_REQ_CREDIT_BUREAU_DAY'\n 'AMT_REQ_CREDIT_BUREAU_WEEK' 'AMT_REQ_CREDIT_BUREAU_MON'\n 'AMT_REQ_CREDIT_BUREAU_QRT' 'AMT_REQ_CREDIT_BUREAU_YEAR'\n 'PREVIOUS_EXISTS' 'REFUSED' 'CANCELLED' 'CANCELLED_TYPE' 'REFUSED_TYPE'\n 'AMT_CREDIT_MAX_OVERDUE_1' 'BALANCE_RATIO' 'ATM_RATIO' 'ATM_D_RATIO'\n 'DAYS_CREDIT' 'CREDIT_DAY_OVERDUE' 'DAYS_CREDIT_ENDDATE' 'AMT_ANNUITY_y'\n 'DAYS_ENDDATE_FACT' 'AMT_CREDIT_MAX_OVERDUE' 'CNT_CREDIT_PROLONG'\n 'AMT_CREDIT_SUM' 'AMT_CREDIT_SUM_DEBT' 'AMT_CREDIT_SUM_LIMIT'\n 'AMT_CREDIT_SUM_OVERDUE' 'DAYS_CREDIT_UPDATE' 'MONTHS_BALANCE_x'\n 'AMT_BALANCE' 'AMT_CREDIT_LIMIT_ACTUAL' 'AMT_DRAWINGS_ATM_CURRENT'\n 'AMT_DRAWINGS_CURRENT' 'AMT_DRAWINGS_OTHER_CURRENT'\n 'AMT_DRAWINGS_POS_CURRENT' 'AMT_INST_MIN_REGULARITY'\n 'AMT_PAYMENT_CURRENT' 'AMT_PAYMENT_TOTAL_CURRENT'\n 'AMT_RECEIVABLE_PRINCIPAL' 'AMT_RECIVABLE' 'AMT_TOTAL_RECEIVABLE'\n 'CNT_DRAWINGS_ATM_CURRENT' 'CNT_DRAWINGS_CURRENT'\n 'CNT_DRAWINGS_OTHER_CURRENT' 'CNT_DRAWINGS_POS_CURRENT'\n 'CNT_INSTALMENT_MATURE_CUM' 'SK_DPD' 'SK_DPD_DEF' 'MONTHS_BALANCE_y'\n 'CNT_INSTALMENT' 'CNT_INSTALMENT_FUTURE' 'NAME_CONTRACT_STATUS'\n 'NUM_INSTALMENT_VERSION' 'NUM_INSTALMENT_NUMBER' 'DAYS_INSTALMENT'\n 'DAYS_ENTRY_PAYMENT' 'AMT_INSTALMENT' 'AMT_PAYMENT']\n"
     ]
    }
   ],
   "source": [
    "test.replace(np.nan, 0, inplace=True)\n",
    "results = regressor.predict(test)\n",
    "\n",
    "import sklearn\n",
    "i=0\n",
    "correct=0\n",
    "incorrect=0\n",
    "ov_correct=0\n",
    "ov_incorrect=0\n",
    "golden_num = 0.19\n",
    "\n",
    "for item in results:\n",
    "    if(item > golden_num):\n",
    "        if test_labels.iloc[i] == 1.0:\n",
    "            #print(\"Correclty Found a loan record to block!!!!!!\")\n",
    "            correct = correct+1\n",
    "        else:\n",
    "            #print(\"Incorrectly Found a loan record to block!!!!!! \"+ str(test_labels.iloc[i]))\n",
    "            incorrect = incorrect+1\n",
    "        results[i] = 1\n",
    "    else:\n",
    "        results[i] = 0\n",
    "    if (item <= golden_num and test_labels.iloc[i] == 1) or (item > golden_num and test_labels.iloc[i] == 0):\n",
    "        ov_incorrect = ov_incorrect + 1\n",
    "    else :\n",
    "        ov_correct = ov_correct + 1\n",
    "    i=i+1\n",
    "\n",
    "rounded_results = np.array(results)\n",
    "rounded_results = rounded_results.round().astype(int)\n",
    "accuracy = sklearn.metrics.accuracy_score(np.array(test_labels), \n",
    "                                    rounded_results , normalize=False)\n",
    "\n",
    "total_rejects = list(test_labels).count(1)\n",
    "print('Number of loan approvals in data :: '+str(list(test_labels).count(0)))\n",
    "print('Number of loan denials in data :: '+str(total_rejects))\n",
    "\n",
    "\n",
    "print(\"Correct Rejects:: \"+ str(correct))\n",
    "print(\"Incorrect Rejects:: \" + str(incorrect))\n",
    "print(\"Recall:: \",correct/total_rejects)\n",
    "print(\"Correct Prediction:: \" + str(ov_correct))\n",
    "print(\"Incorrect Prediction:: \" + str(ov_incorrect))\n",
    "print(\"Accuracy of model is ::\", ov_correct/(ov_correct+ov_incorrect))\n",
    "\n",
    "print(regressor.feature_importances_)\n",
    "print(regressor.n_features_)\n",
    "print(train.columns.values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelfile = 'C:\\\\Users\\\\Apurva\\\\Downloads\\\\courses\\\\credit-risk-challenge\\\\models\\\\credit_risk_model_v5.sav'\n",
    "import pickle\n",
    "pickle.dump(regressor, open(modelfile, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform each feature in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cash loans' 'Revolving loans']\n['F' 'M']\n['N' 'Y']\n['Y' 'N']\n['Unaccompanied' 0 'Family' 'Spouse, partner' 'Group of people' 'Other_B'\n 'Children' 'Other_A']\n['Working' 'State servant' 'Pensioner' 'Commercial associate'\n 'Businessman' 'Student' 'Unemployed']\n['Higher education' 'Secondary / secondary special' 'Incomplete higher'\n 'Lower secondary' 'Academic degree']\n['Married' 'Single / not married' 'Civil marriage' 'Widow' 'Separated']\n['House / apartment' 'With parents' 'Rented apartment'\n 'Municipal apartment' 'Office apartment' 'Co-op apartment']\n[0 'Low-skill Laborers' 'Drivers' 'Sales staff' 'High skill tech staff'\n 'Core staff' 'Laborers' 'Managers' 'Accountants' 'Medicine staff'\n 'Security staff' 'Private service staff' 'Secretaries' 'Cleaning staff'\n 'Cooking staff' 'HR staff' 'Waiters/barmen staff' 'Realty agents'\n 'IT staff']\n['Kindergarten' 'Self-employed' 'Transport: type 3'\n 'Business Entity Type 3' 'Government' 'Industry: type 9' 'School'\n 'Trade: type 2' 'XNA' 'Services' 'Bank' 'Industry: type 3' 'Other'\n 'Trade: type 6' 'Industry: type 12' 'Trade: type 7' 'Postal' 'Medicine'\n 'Housing' 'Business Entity Type 2' 'Construction' 'Military'\n 'Industry: type 4' 'Trade: type 3' 'Legal Services' 'Security'\n 'Industry: type 11' 'University' 'Business Entity Type 1' 'Agriculture'\n 'Security Ministries' 'Transport: type 2' 'Industry: type 7'\n 'Transport: type 4' 'Telecom' 'Emergency' 'Police' 'Industry: type 1'\n 'Transport: type 1' 'Electricity' 'Industry: type 5' 'Hotel' 'Restaurant'\n 'Advertising' 'Mobile' 'Trade: type 1' 'Industry: type 8' 'Realtor'\n 'Cleaning' 'Industry: type 2' 'Trade: type 4' 'Industry: type 6'\n 'Culture' 'Insurance' 'Religion' 'Industry: type 13' 'Industry: type 10'\n 'Trade: type 5']\n[-1  1]\n[ 1 -1]\n[ 1 -1]\n[-1  1]\n[1 0 2 3 7 6 4 5]\n[1 2 4 3 7 6 5]\n[2 1 3 4 5]\n[2 1 3 4 5]\n[1 3 2 4 5 6]\n[ 0 14  5  6 12  2  1  4  3 10 11  9 16  7  8 18 13 15 17]\n[14 10 26  1  3 39  2 24  6 18 38 37  5 41 44 15 29  8 13  9 12 17 30 36\n 49 23 16 25 28 31 19 11 35 20 55 22 27 21 43  7 47 34 32 50 45 46 56 57\n 52 42 54 58 33 40  4 53 48 51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -1.   100. -1000.     1.  -100.  1000.    10.     0.]\n"
     ]
    }
   ],
   "source": [
    "root_test=\"C:\\\\Users\\\\Apurva\\\\Downloads\\\\courses\\\\credit-risk-challenge\\\\data\\\\application_test\"\n",
    "test = open( root_test + \"\\\\application_test.csv\",'r')\n",
    "\n",
    "test_fields = ['SK_ID_CURR','NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY'\n",
    "          ,'CNT_CHILDREN','AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE',\n",
    "          'NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS',\n",
    "          'NAME_HOUSING_TYPE','REGION_POPULATION_RELATIVE','DAYS_BIRTH','DAYS_EMPLOYED'\n",
    "          ,'DAYS_REGISTRATION','DAYS_ID_PUBLISH','OWN_CAR_AGE','FLAG_PHONE','OCCUPATION_TYPE',\n",
    "          'CNT_FAM_MEMBERS','REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY',\n",
    "          'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY','ORGANIZATION_TYPE',\n",
    "          'LIVE_CITY_NOT_WORK_CITY','APARTMENTS_AVG','BASEMENTAREA_AVG',\n",
    "          'YEARS_BEGINEXPLUATATION_AVG','YEARS_BUILD_AVG','EXT_SOURCE_1','EXT_SOURCE_2'\n",
    "           ,'EXT_SOURCE_3', 'AMT_REQ_CREDIT_BUREAU_YEAR','YEARS_BEGINEXPLUATATION_AVG',\n",
    "          'APARTMENTS_AVG','YEARS_BUILD_AVG','COMMONAREA_AVG','ELEVATORS_AVG','YEARS_BUILD_MODE',\n",
    "          'APARTMENTS_MEDI','YEARS_BEGINEXPLUATATION_MEDI','LANDAREA_MEDI','AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "          'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\n",
    "          'AMT_REQ_CREDIT_BUREAU_QRT']\n",
    "\n",
    "dftest = pd.read_csv(test, usecols=test_fields)\n",
    "dftest.replace(np.nan, 0, inplace=True)\n",
    "import numpy as np\n",
    "\n",
    "dftest = initital_cleaning(dftest)\n",
    "dftest = populate_bureau_features(dftest)\n",
    "dftest = populate_credit_card_features(dftest)\n",
    "\n",
    "bureau = open( root_b + \"\\\\bureau.csv\",'r')\n",
    "dftest = add_merged_features(bureau, dftest)\n",
    "\n",
    "dftest1 = dftest.drop(['SK_ID_CURR'], axis=1, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftest1.replace(np.nan, 0, inplace=True)\n",
    "results = regressor.predict(dftest1)\n",
    "test_results = open( root_test + \"\\\\application_results.csv\",'w')\n",
    "test_results.write('SK_ID_CURR,TARGET\\n')\n",
    "for i, row in dftest.iterrows():\n",
    "    predict = results[i]\n",
    "    if predict > golden_num:\n",
    "        predict = 1\n",
    "    else :\n",
    "        predict = 0\n",
    "    test_results.write(str(dftest.at[i, 'SK_ID_CURR']) + ','+ str(predict) + '\\n')    \n",
    "test_results.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
